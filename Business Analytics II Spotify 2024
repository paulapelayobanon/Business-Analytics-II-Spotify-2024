# 1. Import the required libraries

library(rjson)
library(jsonlite)
library(lubridate)
library(gghighlight)
library(tidyverse)
library(knitr)
library(ggdark)
library(plotly)
library(prophet)
library(forecast)

readlines(readr which is TIDYVERSE)
fromJSON(jsonlite)

Sys.setlocale("LC_TIME", "English")


# 2. Import the files

## We have two spotify json files, one until August and another until December
## Import the files separately with the needed adjustments
file.exists("~/Just for fun - R/Spotify Data 2024/my_spotify_data/Spotify Account Data/StreamingHistory_music_0.json")
file_content1 <- readLines("~/Just for fun - R/Spotify Data 2024/my_spotify_data/Spotify Account Data/StreamingHistory_music_0.json")
parsed_data1 <- fromJSON(paste(file_content1, collapse = " "))
streaminghistory1 <- parsed_data1 %>% bind_rows()

file.exists("~/Just for fun - R/Spotify Data 2024/my_spotify_data/Spotify Account Data/StreamingHistory_music_1.json")
file_content2 <- readLines("~/Just for fun - R/Spotify Data 2024/my_spotify_data/Spotify Account Data/StreamingHistory_music_1.json")
parsed_data2 <- fromJSON(paste(file_content2, collapse = " "))
streaminghistory2 <- parsed_data2 %>% bind_rows()

## Merge the files and check how it looks
streaming2024Paula <- bind_rows(streaminghistory1, streaminghistory2)
View(streaming2024Paula)
str(streaming2024Paula)

# 3. Clean both datasets from Paula and Emma

### doing things differently with lubridate
## separating the column endtime into different columns with different info
## too much information on the column endtime!
streaming2024Paula <- streaming2024Paula %>%
  mutate(
    endTime = ymd_hm(endTime),
    year = year(endTime),
    month = month(endTime),
    day = day(endTime),
    weekday = wday(endTime, label = TRUE),
    hour = hour(endTime),
    minute = minute(endTime))

## locale settings to English: they appeared in my device's language
Sys.setlocale("LC_TIME", "English")

## reorder weekday to start on Monday instead of Sunday
streaming2024Paula$weekday <- factor(streaming2024Paula$weekday, levels = c(
  "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))

## reordering columns for clarity - with native subsetting!
streaming2024Paula <- streaming2024Paula[, c("year", "month", "day", "weekday",
                                             "hour", "minute", "artistName",
                                             "trackName", "msPlayed")]

## filtering by year: removing 2023 data - with native subsetting!
streaming2024Paula <- streaming2024Paula[streaming2024Paula$year == 2024, ]

## remove the "year" column since it's now redundant - with native subsetting!
streaming2024Paula <- streaming2024Paula[, -1] # 

## NA values
anyNA(streaming2024Paula) # gave FALSE
summary(is.na(streaming2024Paula)) # gave FALSE

## unknowns:
unknownartistsPaula <- streaming2024Paula[streaming2024Paula$artistName == "Unknown Artist", ]
unknowntracksPaula <- streaming2024Paula[streaming2024Paula$trackName == "Unknown Track", ]
identical(unknownartistsPaula, unknowntracksPaula) # gave TRUE, play View, head, summary
# we decided to get rid of the 140 unknowns since there's really no conclusion we can get
streaming2024Paula <- streaming2024Paula[!(streaming2024Paula$artistName == "Unknown Artist" &
                                   streaming2024Paula$trackName == "Unknown Track"), ]
  
## adding columns seconds, minutes and hours
streaming2024Paula <- streaming2024Paula %>%
  mutate(seconds = round(msPlayed / 1000, 2),
         minutes = round(msPlayed / 60000, 3))

## remove those rows where msPlayed = 0 - we count them as not played
streaming2024Paula <- streaming2024Paula[streaming2024Paula$msPlayed != 0, ]

## using the same logic, remove those rows where seconds < 10 - we count them as skips
streaming2024Paula <- streaming2024Paula[streaming2024Paula$seconds >= 10, ]

##duplicates
duplicatesPaula <- streaming2024Paula %>%
  group_by(artistName, trackName, month, day, hour, minute) %>%
  filter(n() > 1) %>%
  arrange(month, day, hour, minute)
# not real skips, we continue to consider them on the dataset

# 4. Repeat the process with Emma's dataset

file.exists("~/MA IB & ED/Semester 2/Business Analytics II/Project/Project Semester2/spotify1Emma.json")
file_content3 <- readLines("~/MA IB & ED/Semester 2/Business Analytics II/Project/Project Semester2/spotify1Emma.json")
parsed_data3 <- fromJSON(paste(file_content3, collapse = " "))
streaming2024Emma <- parsed_data3 %>% bind_rows()

streaming2024Emma <- streaming2024Emma %>%
  mutate(
    endTime = ymd_hm(endTime),
    year = year(endTime),
    month = month(endTime),
    day = day(endTime),
    weekday = wday(endTime, label = TRUE),
    hour = hour(endTime),
    minute = minute(endTime))

Sys.setlocale("LC_TIME", "English")

streaming2024Emma$weekday <- factor(
  streaming2024Emma$weekday, levels = c("Mon", "Tue", "Wed", "Thu", "Fri",
                                             "Sat", "Sun"))

streaming2024Emma <- streaming2024Emma[, c("year", "month", "day", "weekday",
                                           "hour", "minute", "artistName",
                                           "trackName", "msPlayed")]

streaming2024Emma <- streaming2024Emma[streaming2024Emma$year == 2024, ]
streaming2024Emma <- streaming2024Emma[, -1]


anyNA(streaming2024Emma) # gave FALSE
summary(is.na(streaming2024Emma)) # gave FALSE

unknownartistsEmma <- streaming2024Emma[streaming2024Emma$artistName == "Unknown Artist", ]
unknowntracksEmma <- streaming2024Emma[streaming2024Emma$trackName == "Unknown Track", ]
identical(unknownartistsEmma, unknowntracksEmma) # gave TRUE, play View, head, summary
# we decided to get rid of the 5 unknowns since there's really no conclusion we can get
streaming2024Emma <- streaming2024Emma[!(streaming2024Emma$artistName == "Unknown Artist" &
                                           streaming2024Emma$trackName == "Unknown Track"), ]
streaming2024Emma <- streaming2024Emma %>%
  mutate(seconds = round(msPlayed / 1000, 2),
         minutes = round(msPlayed / 60000, 3))
streaming2024Emma <- streaming2024Emma[streaming2024Emma$msPlayed != 0, ]
streaming2024Emma <- streaming2024Emma[streaming2024Emma$seconds >= 10, ]
duplicatesEmma <- streaming2024Emma %>%
  group_by(artistName, trackName, month, day, hour, minute) %>%
  filter(n() > 1) %>%
  arrange(month, day, hour, minute)
## we continue to consider them on the dataset

## one final cleaning: Paula's dataset spans until December 17, Emma's dataset starts on March 18th
## we filter the datasets so that they include data only from March 18 to December 17
streaming2024Paula <- streaming2024Paula[
  (streaming2024Paula$month > 3) |
    (streaming2024Paula$month == 3 & streaming2024Paula$day >=18), ]
streaming2024Emma <- streaming2024Emma[
  (streaming2024Emma$month < 12) |
    (streaming2024Emma$month == 12 & streaming2024Emma$day <=17), ]

# 5. Import and clean the extra file: most streamed spotify songs 2024
library(readr)
Most_Streamed_Spotify_Songs_2024 <- read_csv("Most Streamed Spotify Songs 2024.csv")
Most_Streamed_Spotify_Songs_2024 <- Most_Streamed_Spotify_Songs_2024[, c(
  "Artist", "Track", "All Time Rank", "Spotify Streams")]
Most_Streamed_Spotify_Songs_2024 <- Most_Streamed_Spotify_Songs_2024[1:100, ]
anyNA(Most_Streamed_Spotify_Songs_2024) #gave TRUE
summary(is.na(Most_Streamed_Spotify_Songs_2024)) # gave 4 streams
NAs <- Most_Streamed_Spotify_Songs_2024[is.na(Most_Streamed_Spotify_Songs_2024$`Spotify Streams`), ]
## not that important for analysis we decided to keep them in the dataset
duplicatesGlobal <- Most_Streamed_Spotify_Songs_2024 %>%
  group_by(Artist, Track, `All Time Rank`, `Spotify Streams`) %>%
  filter(n() > 1) %>%
  arrange(Artist, Track, `All Time Rank`, `Spotify Streams`)
## no duplicates found

# 6. Build the Artists data frame

## Source: https://chartmasters.org/community/records/spotify-most-streamed-artists-2024/
Most_Streamed_Spotify_Artists_2024 <- data.frame(c(1:37),
  c("Taylor Swift", "The Weeknd", "Drake", "Bad Bunny", "Billie Eilish",
    "Ariana Grande", "Kanye West", "Peso Pluma", "Travis Scott", "Bruno Mars",
    "Eminem", "Sabrina Carpenter", "Lana del Rey", "Arijit Singh", "Karol G",
    "Feid", "Kendrick Lamar", "SZA", "Coldplay", "Junior H", "Zach Bryan",
    "Rihanna", "Justin Bieber", "Morgan Wallen", "Fuerza Regida", "Post Malone",
    "Natanael Cano", "Rauw Alejandro", "Pritam", "Metro Boomin", "Olivia Rodrigo",
    "Dua Lipa", "David Guetta", "Linkin Park", "Lady Gaga", "Imagine Dragons",
    "Ed Sheeran"),
  c(28.21, 13.27, 12.11, 12.08, 12.00, 10.03, 9.67, 9.38, 8.41, 8.36, 8.12,
    7.84, 7.73, 7.72, 7.64, 7.61, 6.91, 6.84, 6.75, 6.75, 6.72, 6.49, 6.39,
    6.34, 6.30, 6.29, 6.12, 6.08, 5.99, 5.91, 5.85, 5.74, 5.72, 5.68, 5.63,
    5.26, 5.00))
colnames(Most_Streamed_Spotify_Artists_2024) <- c("Order", "Artist",
                                "Number of streams in billion")

# 7. ANALYSIS

# Time Series Analysis
## using the prophet package
### convert the data back to a date format using lubridate 
### aggregate data for every day
prophetPaula <- streaming2024Paula %>%
  mutate(ds = make_datetime(year = 2024, month = month, day = day)) %>%
  select(ds, everything()) %>%
  select(-month, -day, -weekday, -seconds, -msPlayed) %>%
  group_by(ds) %>%
  summarize(y = sum(minutes)) %>%
  ungroup()
prophetEmma <- streaming2024Emma %>%
  mutate(ds = make_datetime(year = 2024, month = month, day = day)) %>%
  select(ds, everything()) %>%
  select(-month, -day, -weekday, -seconds, -msPlayed) %>%
  group_by(ds) %>%
  summarize(y = sum(minutes)) %>%
  ungroup()
# now the data is prepared to be understood by the prophet package
modelPaula <- prophet(prophetPaula)
modelPaula$params
futurePaula <- make_future_dataframe(modelPaula, 259, freq = "day")
forecastPaula <- predict(modelPaula, futurePaula)
plot(modelPaula, forecastPaula)
prophet_plot_components(modelPaula, forecastPaula)
dyplot.prophet(modelPaula, forecastPaula)

modelEmma <- prophet(prophetEmma)
futureEmma <- make_future_dataframe(modelEmma, 259, freq = "day")
forecastEmma <- predict(modelEmma, futureEmma)
plot(modelEmma, forecastEmma)
prophet_plot_components(modelEmma, forecastEmma)
dyplot.prophet(modelEmma, forecastEmma)






## tsibble
tsPaula <- prophetPaula %>%
  mutate(ds = as_date(ds)) %>%
  as_tsibble(index = ds)
tsEmma <- prophetEmma %>%
  mutate(ds = as_date(ds)) %>%
  as_tsibble(index = ds)
ggplot() +
  geom_line(data = tsPaula, aes(ds, y, color = "Paula")) +
  geom_line(data = tsEmma, aes(ds, y, color = "Emma"))
 

# Venn Diagrams
VennArtists <- list(Paula = unique(streaming2024Paula$artistName),
                    Emma = unique(streaming2024Emma$artistName),
                    Global = Most_Streamed_Spotify_Artists_2024$Artist)
ggvenn(VennArtists, fill_color = c("blue", "red", "green")) +
  labs(title = "2024 Artists Venn Diagram")

VennSongs <- list(Paula = unique(streaming2024Paula$trackName),
                  Emma = unique(streaming2024Emma$trackName),
                  Global = Most_Streamed_Spotify_Songs_2024$Track)
ggvenn(VennSongs, fill_color = c("blue", "red", "green")) +
  labs(title = "2024 Songs Venn Diagram")
# try function geom_venn with ggplot2

commonartists <- intersect(intersect(unique(streaming2024Paula$artistName),
                  unique(streaming2024Emma$artistName)),
                  unique(Most_Streamed_Spotify_Artists_2024$Artist))
commonartists <- data.frame(commonartists)
commonartistsgirls <- data.frame(intersect(unique(streaming2024Paula$artistName),
                                unique(streaming2024Emma$artistName)))

commonsongs <- intersect(intersect(
  unique(streaming2024Paula$trackName),
  unique(streaming2024Emma$trackName)),
  unique(Most_Streamed_Spotify_Songs_2024$Track))
commonsongs <- data.frame(commonsongs)
commonsongsgirls <- data.frame(intersect(unique(streaming2024Paula$trackName),
                                         unique(streaming2024Emma$trackName)))

# Density Ridge Plot
combinedstreaming2024month <- bind_rows(
  prophetPaula %>% mutate(user = "Paula"),
  prophetEmma %>% mutate(user = "Emma")) %>%
  mutate(date = as_date(ds), day_of_month = day(ds),
         month = month(ds, label = TRUE, abbr = FALSE))

ggplot(combinedstreaming2024month, aes(x = y, y = month, fill = user)) +
  geom_density_ridges(alpha = 0.4) +
  scale_fill_manual(values = c("Paula" = "#87CEEB", "Emma" = "#D58A94"), name = "User") +
  scale_x_continuous(breaks = seq(0, 500, by = 30)) +
  labs(title = "Paula vs Emma Streaming", x = "Minutes of Streaming") +
  theme_ridges() +
  theme(legend.position = "none")

# Top10 songs
top10Emma <- streaming2024Emma %>%
  group_by(artistName, trackName) %>%
  summarize(total_mins = sum(minutes), .groups = "drop") %>%
  arrange(desc(total_mins)) %>%
  mutate(total_hours = round(total_mins / 60, 2)) %>%
  slice_head(n =10)
top10Paula <- streaming2024Paula %>%
  group_by(artistName, trackName) %>%
  summarize(total_mins = sum(minutes), .groups = "drop") %>%
  arrange(desc(total_mins)) %>%
  mutate(total_hours = round(total_mins / 60, 2)) %>%
  slice_head(n =10)

ggplot(top10Emma, aes(x = reorder(trackName, total_mins), y = total_mins)) +
  geom_segment(aes(xend = trackName, yend = 0),
               color = "#FF9AA2", linewidth = 1.5) +
  geom_point(size = 8, color = "#FFB7B2", alpha = 0.9) +
  geom_text(aes(label = paste0(round(total_hours, 1), "h")), 
            color = "white", size = 3) +
  coord_flip() +
  labs(title = "Emma's Top 10 Most-Listened Tracks",
       subtitle = "Total listening time in hours",
       x = "", y = "Minutes") +
  theme_clean() +
  theme(plot.title = element_text(face = "bold", color = "#FF85A2"),
        panel.grid.major.y = element_blank())
